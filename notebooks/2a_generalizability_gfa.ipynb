{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import KFold\n",
    "from modules.function import get_elem_count, alt_read_gfa_dataset, PTR, check_cuda, get_metrics\n",
    "from modules.encoder import Encoder1D, EncoderDNN, Encoder\n",
    "import re\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import joblib\n",
    "from modules.representation_schemes import get_vectorized_featues, get_atomic_number_features, get_pettifor_features, get_modified_pettifor_features, get_random_features, get_random_features_dense, random_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "cuda = check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfa_dataset_file = 'gfa_dataset.txt'\n",
    "z_row_column_file = 'Z_row_column.txt'\n",
    "element_property_file = 'element_property.txt'\n",
    "common_path = \"Files_from_GTDL_paper/{}\" \n",
    "gfa_dataset = pickle.load(open(common_path.format(gfa_dataset_file), 'rb'))  \n",
    "RC = pickle.load(open(common_path.format(z_row_column_file), 'rb')) \n",
    "new_index=[int(i[4]) for i in RC]#new order \n",
    "Z_row_column = pickle.load(open(common_path.format(z_row_column_file), 'rb'))\n",
    "[property_name_list,property_list,element_name,_]=pickle.load(open(common_path.format(element_property_file), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_gfa, y, p = alt_read_gfa_dataset()\n",
    "count_dict = get_elem_count(comps_gfa)\n",
    "count_df = pd.DataFrame.from_dict(count_dict, orient='index')\n",
    "count_df.reset_index(inplace=True)\n",
    "count_df.rename({'index':'element',0:'count'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>W</td>\n",
       "      <td>380</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V</td>\n",
       "      <td>500</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nb</td>\n",
       "      <td>1078</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mo</td>\n",
       "      <td>1222</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ti</td>\n",
       "      <td>1930</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Co</td>\n",
       "      <td>2294</td>\n",
       "      <td>10.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cr</td>\n",
       "      <td>2714</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fe</td>\n",
       "      <td>5302</td>\n",
       "      <td>25.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ni</td>\n",
       "      <td>6112</td>\n",
       "      <td>29.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al</td>\n",
       "      <td>7084</td>\n",
       "      <td>33.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   element  count  percent\n",
       "37       W    380     1.82\n",
       "9        V    500     2.40\n",
       "21      Nb   1078     5.17\n",
       "22      Mo   1222     5.86\n",
       "8       Ti   1930     9.25\n",
       "13      Co   2294    10.99\n",
       "10      Cr   2714    13.00\n",
       "12      Fe   5302    25.40\n",
       "14      Ni   6112    29.29\n",
       "4       Al   7084    33.94"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df['percent'] = [np.round(count_df.loc[i,'count']/len(comps_gfa)*100,2) for i in range(count_df.shape[0])]\n",
    "elements = ['Al','Ni','Fe','Cr','Co','Ti','Mo','Nb','V','W']\n",
    "count_df[[el in elements for el in count_df['element'].values]].sort_values('percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260629/291367725.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(comps_gfa)[train_inds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split file written!\n"
     ]
    }
   ],
   "source": [
    "elements = ['Al','Ni','Fe','Cr','Co','Ti','Mo','Nb','V','W']\n",
    "filename = 'misc/gfa_gen_splits.json'\n",
    "if os.path.exists(filename):\n",
    "    with open(filename,'rb') as fid:\n",
    "        gfa_gen_dict = json.load(fid)\n",
    "        print('Split file loaded')\n",
    "else:\n",
    "\n",
    "    gfa_gen_dict = {}\n",
    "    for el in elements:\n",
    "        train_inds, test_inds,all_cv_train, all_cv_test = [],[],[],[]\n",
    "        for i,c in enumerate(comps_gfa):\n",
    "            if el in c.get_el_amt_dict().keys():\n",
    "                train_inds.append(i)\n",
    "            else:\n",
    "                test_inds.append(i)\n",
    "        X_train = np.array(comps_gfa)[train_inds]\n",
    "        kf = KFold(n_splits=5)\n",
    "        for tr, ts in kf.split(X_train):\n",
    "            all_cv_train.append(tr.tolist())\n",
    "            all_cv_test.append(ts.tolist())\n",
    "        gfa_gen_dict[el] = {'train':train_inds,'test':test_inds, 'cv_train':all_cv_train, 'cv_test':all_cv_test}\n",
    "    \n",
    "    with open(filename,'w') as fid:\n",
    "        json.dump(gfa_gen_dict, fid)\n",
    "        print('Split file written!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1D_features_gfa(k:str):\n",
    "    comp_gfa, y, p = alt_read_gfa_dataset()\n",
    "    y = np.array(y).reshape(-1,1).astype('float32')\n",
    "    p = np.array(p).reshape(-1,1).astype('float32')\n",
    "    if k not in ['atomic','pettifor','mod_pettifor','random']:\n",
    "        print('Unsupported format')\n",
    "        return None, None, None\n",
    "    else:\n",
    "        if k == 'atomic':\n",
    "            comp, at_order  = get_atomic_number_features(comp_gfa)\n",
    "        elif k == 'pettifor':\n",
    "            comp, _  = get_pettifor_features(comp_gfa)\n",
    "        elif k == 'mod_pettifor':\n",
    "            comp, _  = get_modified_pettifor_features(comp_gfa)\n",
    "        elif k == 'random':\n",
    "            comp,_ = get_random_features(comp_gfa, random_order)\n",
    "        return comp, y, p\n",
    "\n",
    "def get_dense_features_gfa():\n",
    "    comp_gfa, y, p = alt_read_gfa_dataset()\n",
    "    y = np.array(y).reshape(-1,1).astype('float32')\n",
    "    p = np.array(p).reshape(-1,1).astype('float32') \n",
    "    comp,_ = get_random_features_dense(comp_gfa, random_order)\n",
    "    return comp, y, p\n",
    "\n",
    "def get_ptr_features_gfa(gfa_dataset=gfa_dataset):\n",
    "\n",
    "    gfa_i=[]\n",
    "    gfa_a=[]\n",
    "    gfa_b=[]\n",
    "    gfa_c=[]\n",
    "    to_discard = ['Rf','Db','Sg','Bh','Hs']\n",
    "    for i in  gfa_dataset:\n",
    "        tx_gfa=re.findall('\\[[a-c]?\\]', i)\n",
    "        tx1_element=re.findall('[A-Z][a-z]?', i)#[B, Fe, P,No]\n",
    "        if len(set(tx1_element).intersection(set(to_discard))) == 0:      \n",
    "            gfa_i.extend(tx_gfa)\n",
    "            if tx_gfa[0]=='[a]':\n",
    "                gfa_a.append(gfa_dataset.index(i))\n",
    "            elif tx_gfa[0]=='[b]':\n",
    "                gfa_b.append(gfa_dataset.index(i)) \n",
    "            else:\n",
    "                gfa_c.append(gfa_dataset.index(i))\n",
    "        \n",
    "    gfa_data_form=[]\n",
    "    gfa_data_form_p = []\n",
    "    gfa_data_form_b=[]\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#map raw data to 2-D image using PTR\n",
    "    for i in gfa_a:\n",
    "        x,p,y = PTR(gfa_dataset[i])\n",
    "        gfa_data_form=gfa_data_form+x\n",
    "        gfa_data_form_p = gfa_data_form_p+p\n",
    "        gfa_data_form_b=gfa_data_form_b+y\n",
    "    for i in gfa_c:\n",
    "        x,p,y = PTR(gfa_dataset[i])\n",
    "        gfa_data_form=gfa_data_form+x\n",
    "        gfa_data_form_p = gfa_data_form_p+p\n",
    "        gfa_data_form_b=gfa_data_form_b+y \n",
    "    for i in gfa_b:\n",
    "        x,p,y = PTR(gfa_dataset[i])\n",
    "        gfa_data_form=gfa_data_form+x\n",
    "        gfa_data_form_p = gfa_data_form_p+p\n",
    "        gfa_data_form_b=gfa_data_form_b+y\n",
    "\n",
    "    X_all = np.array(gfa_data_form).reshape(-1, 1,9, 18).astype('float32') \n",
    "    y_all = np.array(gfa_data_form_b).reshape(-1,1).astype('float32')\n",
    "    p_all = np.array(gfa_data_form_p).reshape(-1,1).astype('float32')\n",
    "    return X_all, y_all, p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveloc = 'saved_models/LOEO_Encoders'\n",
    "if not os.path.exists(saveloc):\n",
    "    os.makedirs(f'{saveloc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010243654251098633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dfc4805f274beb8e0a73662d72f1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense : Element Al, Fold 0, Epoch : 1, Loss : 59.46879905462265\n",
      "dense : Element Al, Fold 0, Epoch : 500, Loss : 5.203987020999193\n",
      "dense : Element Al, Fold 0, Epoch : 1000, Loss : 4.191072904504836\n",
      "dense : Element Al, Fold 0, Epoch : 1500, Loss : 3.908863263204694\n",
      "dense : Element Al, Fold 0, Epoch : 2000, Loss : 3.772492978256196\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009945869445800781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97609669b5e846caab27b5669eb72af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense : Element Al, Fold 1, Epoch : 1, Loss : 60.659728050231934\n",
      "dense : Element Al, Fold 1, Epoch : 500, Loss : 4.441414857748896\n",
      "dense : Element Al, Fold 1, Epoch : 1000, Loss : 3.7315723549108952\n",
      "dense : Element Al, Fold 1, Epoch : 1500, Loss : 3.4324506116099656\n",
      "dense : Element Al, Fold 1, Epoch : 2000, Loss : 3.312455483013764\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011800527572631836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48af860bab8941aba30b628fb6954b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense : Element Al, Fold 2, Epoch : 1, Loss : 57.727927446365356\n",
      "dense : Element Al, Fold 2, Epoch : 500, Loss : 4.739594083279371\n",
      "dense : Element Al, Fold 2, Epoch : 1000, Loss : 3.9628490114118904\n",
      "dense : Element Al, Fold 2, Epoch : 1500, Loss : 4.0655128138605505\n",
      "dense : Element Al, Fold 2, Epoch : 2000, Loss : 3.1386625161394477\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010319948196411133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68985c95b25428e91c679d6804861a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense : Element Al, Fold 3, Epoch : 1, Loss : 51.827803552150726\n",
      "dense : Element Al, Fold 3, Epoch : 500, Loss : 5.852062711492181\n",
      "dense : Element Al, Fold 3, Epoch : 1000, Loss : 4.74813527520746\n",
      "dense : Element Al, Fold 3, Epoch : 1500, Loss : 4.108698435593396\n"
     ]
    }
   ],
   "source": [
    "result_file = 'results/gfa_LOEO_stats.json'\n",
    "methods = ['dense','atomic','pettifor','mod_pettifor','random','PTR']\n",
    "batch = 64\n",
    "num_iterations = 2000\n",
    "log_interval = int(5e2)\n",
    "results_dict = {}\n",
    "for method in methods:\n",
    "    results_dict[method] = {}\n",
    "    if method == 'dense':\n",
    "        X, y , p = get_dense_features_gfa()    \n",
    "    elif method in ['atomic','pettifor','mod_pettifor','random']:\n",
    "        X,y,p = get_1D_features_gfa(method)     \n",
    "    elif method == 'PTR':\n",
    "        X,y,p = get_ptr_features_gfa()\n",
    "    for k in gfa_gen_dict.keys():\n",
    "        results_dict[method][k] = {}\n",
    "        f1_max = 0\n",
    "        best_fold_model = 0\n",
    "        LOEO_dict = {'Fold_stats':{}}\n",
    "        test_inds = gfa_gen_dict[k]['test']\n",
    "        X_test = X[test_inds]\n",
    "        y_test = y[test_inds]\n",
    "        p_test = p[test_inds]\n",
    "        if X_test.dtype != torch.float32:\n",
    "            X_test = torch.from_numpy(X_test)\n",
    "        if p_test.dtype != torch.float32:\n",
    "            p_test = torch.from_numpy(p_test)\n",
    "        if cuda:\n",
    "            X_test = X_test.cuda()\n",
    "            p_test = p_test.cuda()\n",
    "        cv_train_inds, cv_test_inds = gfa_gen_dict[k]['cv_train'],gfa_gen_dict[k]['cv_test']\n",
    "        for i in range(len(cv_train_inds)):\n",
    "            fold_train_inds, fold_test_inds = cv_train_inds[i], cv_test_inds[i]\n",
    "            X_train_fold,y_train_fold ,p_train_fold  = X[fold_train_inds], y[fold_train_inds], p[fold_train_inds]\n",
    "            X_test_fold, y_test_fold, p_test_fold = X[fold_test_inds], y[fold_test_inds], p[fold_test_inds]\n",
    "            Xy = [(X_train_fold[i],y_train_fold[i],p_train_fold[i]) for i in range(len(y_train_fold))]\n",
    "            train_loader = DataLoader(Xy, batch_size = batch , shuffle=True)\n",
    "            if X_test_fold.dtype != torch.float32:\n",
    "                X_test_fold = torch.from_numpy(X_test_fold)\n",
    "            if p_test_fold.dtype != torch.float32:\n",
    "                p_test_fold = torch.from_numpy(p_test_fold)\n",
    "            if method == 'dense':\n",
    "                encoder = EncoderDNN(X_train_fold.shape[-1],3,42,1)\n",
    "            elif method in ['atomic','pettifor','mod_pettifor','random']:\n",
    "                encoder = Encoder1D(1,1)\n",
    "            elif method == 'PTR':\n",
    "                encoder = Encoder(1,1)\n",
    "            \n",
    "            if cuda:\n",
    "                encoder = encoder.cuda()\n",
    "                X_test_fold, p_test_fold = X_test_fold.cuda(), p_test_fold.cuda()\n",
    "            e_optimizer = optim.Adam(encoder.parameters(),lr = 2e-4)\n",
    "            for iter in tqdm.notebook.tqdm(range(num_iterations)):\n",
    "                train_loss = 0.0\n",
    "                for data in train_loader:\n",
    "                    X_t,y_t,p_t = data\n",
    "                    if cuda:\n",
    "                        X_t = X_t.cuda()\n",
    "                        y_t = y_t.cuda()\n",
    "                        p_t = p_t.cuda()\n",
    "                    e_optimizer.zero_grad()\n",
    "                    target = encoder(X_t,p_t)\n",
    "                    if cuda:\n",
    "                        target = target.cuda()\n",
    "                    e_error = torch.nn.BCELoss()(target,y_t)\n",
    "                    e_error.backward(retain_graph=True)\n",
    "                    e_optimizer.step()\n",
    "                    train_loss += e_error.cpu().item()\n",
    "                if iter == 0 or (iter + 1) % log_interval == 0:  \n",
    "                    print('{} : Element {}, Fold {}, Epoch : {}, Loss : {}'.format(method,k,i,iter+1,train_loss))\n",
    "            spec_saveloc = os.path.join(saveloc,method)\n",
    "            if not os.path.exists(spec_saveloc):\n",
    "                os.makedirs(f'{spec_saveloc}')\n",
    "            joblib.dump(encoder,os.path.join(spec_saveloc,'LOEOEncoder_{}_fold{}.pt'.format(k,i)))\n",
    "            y_predict_fold = (encoder(X_test_fold,p_test_fold)).to('cpu').detach().numpy()\n",
    "            metrics_fold = get_metrics(y_test_fold,np.round(y_predict_fold))\n",
    "            LOEO_dict['Fold_stats'][i] = metrics_fold\n",
    "            y_predict = (encoder(X_test,p_test)).to('cpu').detach().numpy()\n",
    "            metrics = get_metrics(y_test,np.round(y_predict))\n",
    "            f1_predict = metrics[3]\n",
    "            if f1_predict>f1_max:\n",
    "                f1_max = f1_predict\n",
    "                best_fold_model = i\n",
    "                LOEO_dict['Best_f1'] = f1_max\n",
    "                LOEO_dict['Best_fold'] = best_fold_model\n",
    "        results_dict[method][k] = LOEO_dict\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file,'rb') as fid:\n",
    "                data_file = json.load(fid)\n",
    "            updated_file = data_file|results_dict\n",
    "            with open(result_file,'w') as f:\n",
    "                json.dump(updated_file,f)\n",
    "        else:\n",
    "            with open(result_file, 'w') as f:\n",
    "                json.dump(results_dict, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('representations': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d6d4f329abd04bfe6379b099819ba9ed35c0bee691259b7aa14222222f8ecb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.function import get_elem_count, alt_read_gfa_dataset, check_cuda, get_metrics, image, read_gfa_dataset\n",
    "from modules.representation_schemes import get_atomic_number_features, get_pettifor_features, get_modified_pettifor_features, get_random_features, get_random_features_dense, random_order_alpha, get_1D_features_gfa, get_dense_features_gfa\n",
    "from modules.encoder import Encoder1D, EncoderDNN, Encoder\n",
    "import re\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import joblib\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold dictionary loaded!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "kfold_loc = 'misc/gfa_kfold.pkl'\n",
    "create_new = False\n",
    "if os.path.exists(kfold_loc) and not create_new:\n",
    "    with open(kfold_loc,'rb') as fid:\n",
    "        fold_dict = pickle.load(fid)\n",
    "    print('Fold dictionary loaded!')\n",
    "else:\n",
    "    fold_dict = {}\n",
    "    X, y, _ = get_dense_features_gfa()\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 0, shuffle=True)\n",
    "    for i,(train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        fold_dict[i] = {'train_inds':train_index, 'test_inds':test_index}\n",
    "    with open(kfold_loc,'wb') as fid:\n",
    "        pickle.dump(fold_dict,fid)\n",
    "    print('Fold dictionary created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method : random\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010466337203979492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4615644ed2e4bce816532211e0475ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss : 182.2973966896534\n",
      "Epoch : 500, Loss : 53.34674897044897\n",
      "Epoch : 1000, Loss : 43.749323051422834\n",
      "Epoch : 1500, Loss : 38.012205604463816\n",
      "Epoch : 2000, Loss : 33.06775265187025\n",
      "accuracy : 0.9387,precision : 0.94,recall : 0.9387,F1 : 0.9391\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012550592422485352,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5186a3c286754228898687415f0253a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss : 183.68972831964493\n",
      "Epoch : 500, Loss : 48.916234750300646\n",
      "Epoch : 1000, Loss : 38.17846620082855\n",
      "Epoch : 1500, Loss : 32.83130997419357\n",
      "Epoch : 2000, Loss : 29.041188701987267\n",
      "accuracy : 0.9463,precision : 0.9463,recall : 0.9463,F1 : 0.9463\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012052059173583984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a537757d4e894ec28de38013198e910c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss : 184.38523265719414\n",
      "Epoch : 500, Loss : 51.61269997432828\n",
      "Epoch : 1000, Loss : 43.10521576553583\n",
      "Epoch : 1500, Loss : 38.169378567487\n",
      "Epoch : 2000, Loss : 34.682810032740235\n",
      "accuracy : 0.932,precision : 0.9318,recall : 0.932,F1 : 0.9311\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009965658187866211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b0042be4554014b9ff8f7193ead092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss : 182.16963243484497\n",
      "Epoch : 500, Loss : 47.06188079342246\n",
      "Epoch : 1000, Loss : 36.04837105423212\n",
      "Epoch : 1500, Loss : 30.444127559661865\n",
      "Epoch : 2000, Loss : 27.06372257322073\n",
      "accuracy : 0.9459,precision : 0.9464,recall : 0.9459,F1 : 0.9461\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010250329971313477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19fc2f9b96c4a77b1e98d5cfa10b7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss : 183.01399743556976\n",
      "Epoch : 500, Loss : 43.074997156858444\n"
     ]
    }
   ],
   "source": [
    "saveloc = 'saved_models/Encoders'\n",
    "if not os.path.exists(saveloc):\n",
    "    os.makedirs(f'{saveloc}')\n",
    "methods = ['random','random-tr','pettifor','mod_pettifor','PTR']\n",
    "#methods = ['dense','atomic','random','random-tr','pettifor','mod_pettifor','PTR']\n",
    "if os.path.exists('results/gfa_predict_results.json'):\n",
    "    with open('results/gfa_predict_results.json','rb') as fid:\n",
    "        sup_metrics_dict = json.load(fid)\n",
    "else:\n",
    "    sup_metrics_dict = {}\n",
    "for method in methods:\n",
    "    print('Method : {}'.format(method))\n",
    "    metrics_list = {}\n",
    "    if method == 'dense':\n",
    "        X, y, p = get_dense_features_gfa()    \n",
    "    elif method in ['atomic','pettifor','mod_pettifor','random']:\n",
    "        X, y, p = get_1D_features_gfa(method)    \n",
    "    elif method == 'PTR':\n",
    "        X, y, p = read_gfa_dataset()\n",
    "    for i in fold_dict.keys():\n",
    "        i_tr, i_te = fold_dict[i]['train_inds'], fold_dict[i]['test_inds']\n",
    "        X_train, X_test = X[i_tr], X[i_te]\n",
    "        y_train, y_test = y[i_tr], y[i_te]\n",
    "        p_train, p_test = p[i_tr], p[i_te]\n",
    "        batch = 64\n",
    "        Xy = [(X_train[i],y_train[i],p_train[i]) for i in range(len(y_train))]\n",
    "        train_loader = DataLoader(Xy, batch_size = batch , shuffle=True)\n",
    "        if method in ['atomic','pettifor','mod_pettifor','random','random-tr']:\n",
    "            type = 0\n",
    "            encoder = Encoder1D(1,1)\n",
    "        elif method == 'dense':\n",
    "            type = 1\n",
    "            encoder = EncoderDNN(X.shape[-1],3,42,1)\n",
    "        else:\n",
    "            type = 2\n",
    "            encoder = Encoder(1,1)\n",
    "        e_optimizer = optim.Adam(encoder.parameters(),lr = 2e-4)\n",
    "        num_iterations = 2000\n",
    "        cuda = check_cuda()\n",
    "        if cuda:\n",
    "            encoder = encoder.cuda()\n",
    "        log_interval = int(5e2)\n",
    "        for iter in tqdm.notebook.tqdm(range(num_iterations)):\n",
    "            train_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                X_temp, y_temp, p_temp = data\n",
    "                if cuda:\n",
    "                    X_temp = X_temp.cuda()\n",
    "                    y_temp = y_temp.cuda()\n",
    "                    p_temp = p_temp.cuda()\n",
    "                e_optimizer.zero_grad()\n",
    "                target = encoder(X_temp,p_temp)\n",
    "                if cuda:\n",
    "                    target = target.cuda()\n",
    "                e_error = torch.nn.BCELoss()(target,y_temp)\n",
    "                e_error.backward(retain_graph=True)\n",
    "                e_optimizer.step()\n",
    "                train_loss += e_error.cpu().item()\n",
    "            if iter == 0 or (iter + 1) % log_interval == 0:  \n",
    "                print('Epoch : {}, Loss : {}'.format(iter+1,train_loss))\n",
    "        spec_saveloc = os.path.join(saveloc,method)\n",
    "        if not os.path.exists(spec_saveloc):\n",
    "            os.makedirs(f'{spec_saveloc}')\n",
    "        model_scripted = torch.jit.script(encoder.cpu())\n",
    "        model_scripted.save(os.path.join(spec_saveloc,'Encoder{}D_{}_fold{}.pt'.format(type,method,i)))\n",
    "        if X_test.dtype != torch.float32:\n",
    "            X_test = torch.from_numpy(X_test)\n",
    "        if p_test.dtype != torch.float32:\n",
    "            p_test = torch.from_numpy(p_test)\n",
    "        with torch.no_grad():\n",
    "            y_predict = (encoder(X_test,p_test)).to('cpu').detach().numpy()\n",
    "        metrics = get_metrics(y_test,np.round(y_predict))\n",
    "        metrics_list[i] = metrics\n",
    "        print('accuracy : {},precision : {},recall : {},F1 : {}'.format(metrics[0],metrics[1],metrics[2],metrics[3]))\n",
    "    sup_metrics_dict[method] = metrics_list\n",
    "    with open('results/gfa_predict_results.json','w') as f:\n",
    "        json.dump(sup_metrics_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('representations': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d6d4f329abd04bfe6379b099819ba9ed35c0bee691259b7aa14222222f8ecb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
